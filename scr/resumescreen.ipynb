{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/riz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/riz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import CoherenceModel\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = pd.read_csv('../data/UpdatedResumeDataSet.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. NER implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained bert model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "\n",
    "# Load pre-trained spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# NER pipeline\n",
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec',\n",
       " 'tagger',\n",
       " 'parser',\n",
       " 'attribute_ruler',\n",
       " 'lemmatizer',\n",
       " 'ner',\n",
       " 'entity_ruler']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "skill_pattern_path = \"../data/jz_skill_patterns.jsonl\"\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.from_disk(skill_pattern_path)\n",
    "nlp.pipe_names\n",
    "\n",
    "def get_skills(text):\n",
    "    doc = nlp(text)\n",
    "    myset = []\n",
    "    subset = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"SKILL\":\n",
    "            subset.append(ent.text)\n",
    "    myset.append(subset)\n",
    "    return subset\n",
    "\n",
    "\n",
    "def unique_skills(x):\n",
    "    return list(set(x))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract named entities using bert ner\n",
    "def extract_entities_bert(resume_text):\n",
    "    entities = ner_pipeline(resume_text)\n",
    "    # Further processing to extract specific entities like name, education, etc.\n",
    "    # This might require custom logic based on the structure of your resumes\n",
    "    return entities\n",
    "\n",
    "# Function to extract named entities using spaCy\n",
    "def extract_entities_spacy(resume_text):\n",
    "    doc = nlp(resume_text)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Category                                     Entities_spacy  \\\n",
      "0    Data Science  [(Sql, PERSON), (Java, PERSON), (JavaScript/JQ...   \n",
      "1    Data Science  [(May 2013 to, DATE), (May 2017, DATE), (Expri...   \n",
      "2    Data Science  [(Control System Design, ORG), (Web Developmen...   \n",
      "3    Data Science  [(Tableau, GPE), (SAP HANA SQL, ORG), (SAP HAN...   \n",
      "4    Data Science  [(MCA, ORG), (YMCAUST, ORG), (Faridabad, GPE),...   \n",
      "..            ...                                                ...   \n",
      "957       Testing  [(MS, GPE), (Basic Excel, PRODUCT), (Loyalty &...   \n",
      "958       Testing  [(Team Player, ORG), (DECLARATION, PERSON), (J...   \n",
      "959       Testing  [(Eagerness, NORP), (Competitive, ORG), (Janua...   \n",
      "960       Testing  [(SKILLS & SOFTWARE, ORG), (MS-Power Point, OR...   \n",
      "961       Testing  [(Skill Set OS, PERSON), (Windows XP/7/8/8.1/1...   \n",
      "\n",
      "                                         Entities_bert  \n",
      "0    [{'entity': 'I-MISC', 'score': 0.57808983, 'in...  \n",
      "1    [{'entity': 'I-ORG', 'score': 0.9233876, 'inde...  \n",
      "2    [{'entity': 'I-MISC', 'score': 0.4734587, 'ind...  \n",
      "3    [{'entity': 'I-ORG', 'score': 0.62514687, 'ind...  \n",
      "4    [{'entity': 'I-ORG', 'score': 0.9732521, 'inde...  \n",
      "..                                                 ...  \n",
      "957  [{'entity': 'I-ORG', 'score': 0.71640754, 'ind...  \n",
      "958  [{'entity': 'I-LOC', 'score': 0.8010248, 'inde...  \n",
      "959  [{'entity': 'I-ORG', 'score': 0.5006158, 'inde...  \n",
      "960  [{'entity': 'I-ORG', 'score': 0.94152266, 'ind...  \n",
      "961  [{'entity': 'I-MISC', 'score': 0.9764082, 'ind...  \n",
      "\n",
      "[962 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "resume_text['Entities_spacy'] = resume_text['Resume'].apply(extract_entities_spacy)\n",
    "resume_text['Entities_bert'] = resume_text['Resume'].apply(extract_entities_bert)\n",
    "\n",
    "# Display the new DataFrame with extracted entities\n",
    "print(resume_text[['Category', 'Entities_spacy', 'Entities_bert']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = resume_text.iloc[:5]\n",
    "\n",
    "# Initialize an empty list to store the transformed data\n",
    "transformed_data = []\n",
    "\n",
    "# Iterate over each row\n",
    "for index, row in selected_rows.iterrows():\n",
    "    # Iterate over each entity in the row\n",
    "    for entity in row['Entities_bert']:\n",
    "        # Append the entity data to the transformed_data list\n",
    "        transformed_data.append({\n",
    "            'Row': index,\n",
    "            'Entity': entity['entity'],\n",
    "            'Score': entity['score'],\n",
    "            'Index': entity['index']\n",
    "            # Add more fields here as needed\n",
    "        })\n",
    "\n",
    "# Convert the transformed data into a DataFrame\n",
    "transformed_df = pd.DataFrame(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Row  Entity     Score  Index\n",
      "0      0  I-MISC  0.578090      6\n",
      "1      0   I-ORG  0.379557     33\n",
      "2      0  I-MISC  0.896526     37\n",
      "3      0  I-MISC  0.978586     39\n",
      "4      0  I-MISC  0.774978     40\n",
      "..   ...     ...       ...    ...\n",
      "290    4   I-ORG  0.427012     16\n",
      "291    4  I-MISC  0.964054     60\n",
      "292    4  I-MISC  0.971787     73\n",
      "293    4   I-ORG  0.769654    106\n",
      "294    4   I-ORG  0.793049    108\n",
      "\n",
      "[295 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(transformed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
